{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Gluon] Convolutional Neural Network for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## http://www.cs.cornell.edu/people/pabo/movie-review-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 전처리:\n",
    "## https://github.com/apache/incubator-mxnet/tree/master/example/cnn_text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sentences(url):\n",
    "    \"\"\"\n",
    "    Download sentences from specified URL. \n",
    "    \n",
    "    Strip trailing newline, convert to Unicode.\n",
    "    \"\"\"\n",
    "    \n",
    "    remote_file = urlopen(url)\n",
    "    return [line.decode('Latin1').strip() for line in remote_file.readlines()]\n",
    "    \n",
    "def load_data_and_labels():\n",
    "    \"\"\"\n",
    "    Loads polarity data from files, splits the data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    positive_examples = download_sentences('https://raw.githubusercontent.com/yoonkim/CNN_sentence/master/rt-polarity.pos')\n",
    "    negative_examples = download_sentences('https://raw.githubusercontent.com/yoonkim/CNN_sentence/master/rt-polarity.neg')\n",
    "    \n",
    "    # Tokenize\n",
    "    x_text = positive_examples + negative_examples\n",
    "    x_text = [clean_str(sent).split(\" \") for sent in x_text]\n",
    "\n",
    "    # Generate labels\n",
    "    positive_labels = [1 for _ in positive_examples]\n",
    "    negative_labels = [0 for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    return x_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning.\n",
    "    Original from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences(sentences, padding_word=\"\"):\n",
    "    \"\"\"\n",
    "    Pads all sentences to be the length of the longest sentence.\n",
    "    Returns padded sentences.\n",
    "    \"\"\"\n",
    "    ## sentences 길이 중 가장 긴 길이 기준\n",
    "    sequence_length = max(len(x) for x in sentences)\n",
    "    \n",
    "    ## padding은 문장에 따라 가변적으로 생성\n",
    "    padded_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        ## 문장길이 - 현재 sentence\n",
    "        num_padding = sequence_length - len(sentence)\n",
    "        ## 문장 뒤에 padding\n",
    "        new_sentence = sentence + [padding_word] * num_padding\n",
    "        padded_sentences.append(new_sentence)\n",
    "        \n",
    "    return padded_sentences, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "sentences, labels = load_data_and_labels()\n",
    "# padding 처리\n",
    "sentences_padded, sequence_length = pad_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print (sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다른 모형에서도 동일한 데이터 사용을 위해 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data_sets.pickle', 'wb') as f:\n",
    "    pickle.dump(pd.DataFrame.from_dict({'X':[' '.join(i) for i in sentences], 'Y':labels}), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences And Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eda(idx):\n",
    "    print ('Orgin: ' + ' '.join(sentences[idx]))\n",
    "    print ('Padded: ' + '_'.join(sentences_padded[idx]))\n",
    "    print ('Label: ' + str(labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orgin: this is a film well worth seeing , talking and singing heads and all\n",
      "Padded: this_is_a_film_well_worth_seeing_,_talking_and_singing_heads_and_all__________________________________________\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print_eda(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orgin: at its best , queen is campy fun like the vincent price horror classics of the '60s at its worst , it implodes in a series of very bad special effects\n",
      "Padded: at_its_best_,_queen_is_campy_fun_like_the_vincent_price_horror_classics_of_the_'60s_at_its_worst_,_it_implodes_in_a_series_of_very_bad_special_effects_________________________\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "print_eda(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5331, 0: 5331})\n"
     ]
    }
   ],
   "source": [
    "print (Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Text to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary mapping from token to index based on the sentences.\n",
    "    Returns vocabulary mapping and inverse vocabulary mapping.\n",
    "    \"\"\"\n",
    "    # Build vocabulary\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    \n",
    "    # Mapping from index to word\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    \n",
    "    # Mapping from word to index\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    \n",
    "    return vocabulary, vocabulary_inv\n",
    "\n",
    "vocabulary, vocabulary_inv = build_vocab(sentences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(itertools.chain(*sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 10194), (',', 10037), ('a', 7341), ('and', 6264), ('of', 6148)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_data(sentences, labels, vocabulary):\n",
    "    \"\"\"\n",
    "    Maps sentences and labels to vectors based on a vocabulary.\n",
    "    \"\"\"\n",
    "    x = np.array([\n",
    "            [vocabulary[word] for word in sentence]\n",
    "            for sentence in sentences])\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = build_input_data(sentences_padded, labels, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1   565     7  2633     6    22     1  3369   887     8   100  5598\n",
      "     4    11    65     8   240     6    73     3  3913    57  2948    34\n",
      "  1489  2393     2  2394 10111  1708  7197    42   937 10112     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', 'conan', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean', 'claud', 'van', 'damme', 'or', 'steven', 'segal', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print (sentences_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (vocabulary['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "print (vocabulary_inv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split: 9662/1000\n",
      "train shape: (9662, 56)\n",
      "Test shape: (1000, 56)\n",
      "vocab_size 18766\n",
      "sentence max words 56\n"
     ]
    }
   ],
   "source": [
    "# split train/test set\n",
    "# there are a total of 10662 labeled examples to train on\n",
    "x_train, x_test = x_shuffled[:-1000], x_shuffled[-1000:]\n",
    "y_train, y_test = y_shuffled[:-1000], y_shuffled[-1000:]\n",
    "\n",
    "sentence_size = x_train.shape[1]\n",
    "\n",
    "print('Train/Test split: %d/%d' % (len(y_train), len(y_test)))\n",
    "print('train shape:', x_train.shape)\n",
    "print('Test shape:', x_test.shape)\n",
    "print('vocab_size', vocab_size)\n",
    "print('sentence max words', sentence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon, init\n",
    "from mxnet.gluon.data import ArrayDataset, DataLoader\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewDataSet(ArrayDataset):\n",
    "    # We pre-process the documents on the fly\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[0][idx], self._data[1][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieReviewDataSet(x_train, y_train)\n",
    "test_dataset = MovieReviewDataSet(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='discard')\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx = mx.gpu() # to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu() # to run on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FILTERS = 256 # number of convolutional filters per convolutional layer\n",
    "NUM_OUTPUTS = len(set(labels)) # number of classes\n",
    "DROPOUT_RATE = 0.5 # probability of node drop out\n",
    "LEARNING_RATE = 0.01 # learning rate of the gradient\n",
    "EMB_OUT = 128\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "FULLY_CONNECTED = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM = 0.9 # momentum of the gradient\n",
    "WDECAY = 0.00001 # regularization term to limit size of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN_1D_00(gluon.HybridBlock):\n",
    "    def __init__(self, vocab_size, sequence_length, embed_size, conv_channel, filter_sizes, num_classes, batch_size, **kwargs):\n",
    "        self.conv_channel = conv_channel\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        super(TextCNN_1D_00, self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "                        \n",
    "            self.embed = nn.Embedding(input_dim=vocab_size, output_dim=embed_size)\n",
    "\n",
    "            self.conv0 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[0], activation='relu')\n",
    "            self.pool0 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[0] + 1))\n",
    "                        \n",
    "            self.conv1 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[1], activation='relu')\n",
    "            self.pool1 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[1] + 1))\n",
    "            \n",
    "            self.conv2 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[2], activation='relu')\n",
    "            self.pool2 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[2] + 1))\n",
    "            \n",
    "            self.drop1 = nn.Dropout(0.5)\n",
    "            self.out = nn.Dense(num_classes)\n",
    "           \n",
    "    def hybrid_forward(self, F, x):\n",
    "        ## batch * 56\n",
    "        ## x\n",
    "        \n",
    "        ## batch * 56 > batch * 56 * 128\n",
    "        embedded_vectors = self.embed(x)\n",
    "        \n",
    "        ## batch *  56 * 128 > batch * 128 * 56\n",
    "        embedded_vectors = F.swapaxes(embedded_vectors, 1,2)\n",
    "                \n",
    "        \n",
    "        ### '나는 공부를 합니다' -> 2차원이라고 해도 나는 공부를을 묶어야한다 \n",
    "        \n",
    "        ## Output Size\n",
    "        #(W - F_w + 2*P)/S_w + 1  : W = 폭, F = 필터 폭, P = padding 사이즈, S = Stride 사이즈 : (56 - 3 + 2*0)/1 + 1 = 54\n",
    "        #(H - F_h + 2*P)/S_h + 1  : \n",
    "        \n",
    "        ## batch * 128 * 56 > batch * 256 * 54 \n",
    "        conv0_out = self.conv0(embedded_vectors) ## NCW\n",
    "        ## batch * 128 * 56 > batch * 256 * 53\n",
    "        conv1_out = self.conv1(embedded_vectors)\n",
    "        ## batch * 128 * 56 > batch * 256 * 52\n",
    "        conv2_out = self.conv2(embedded_vectors)\n",
    "\n",
    "        ## batch * 256 * 54 > batch * 256 * 1: pool_size(54)\n",
    "        pool0_out = self.pool0(conv0_out)\n",
    "        ## batch * 256 * 53 > batch * 256 * 1: pool_size(53)\n",
    "        pool1_out = self.pool1(conv1_out)\n",
    "        ## batch * 256 * 52 > batch * 256 * 1: pool_size(52)\n",
    "        pool2_out = self.pool2(conv2_out)\n",
    "        \n",
    "        ## batch * [[256 * 1], [256 * 1], [256 * 1]]  \n",
    "        con_list = [pool0_out, pool1_out, pool2_out]\n",
    "                \n",
    "        ## batch * [768* 1] : 768 = 256 *3\n",
    "        fc1_input = F.concat(*con_list, dim=1)\n",
    "        \n",
    "        ## batch * [768 * 1]\n",
    "        fc1_output = self.drop1(fc1_input)\n",
    "                                        \n",
    "        ## batch * 2    \n",
    "        output = self.out(fc1_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1d_00 = TextCNN_1D_00(vocab_size, sequence_length, EMB_OUT, NUM_FILTERS, FILTER_SIZES, NUM_OUTPUTS, BATCH_SIZE)\n",
    "shape = (8, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speed improvement, compile the network but no in-depth debugging possible\n",
    "hybridize = True \n",
    "if hybridize:\n",
    "    net_1d_00.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN_1D_00(\n",
      "  (embed): Embedding(18766 -> 128, float32)\n",
      "  (conv0): Conv1D(None -> 256, kernel_size=(3,), stride=(1,), Activation(relu))\n",
      "  (pool0): MaxPool1D(size=(54,), stride=(54,), padding=(0,), ceil_mode=False)\n",
      "  (conv1): Conv1D(None -> 256, kernel_size=(4,), stride=(1,), Activation(relu))\n",
      "  (pool1): MaxPool1D(size=(53,), stride=(53,), padding=(0,), ceil_mode=False)\n",
      "  (conv2): Conv1D(None -> 256, kernel_size=(5,), stride=(1,), Activation(relu))\n",
      "  (pool2): MaxPool1D(size=(52,), stride=(52,), padding=(0,), ceil_mode=False)\n",
      "  (drop1): Dropout(p = 0.5, axes=())\n",
      "  (out): Dense(None -> 2, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (net_1d_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                                        Output Shape            Param #     Previous Layer                  \n",
      "========================================================================================================================\n",
      "data(null)                                          56                      0                                           \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_embedding0_fwd(Embedding)            56x128                  0           data                            \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_swapaxes0(SwapAxis)                  128x56                  0           textcnn_1d_001_embedding0_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv0_fwd(Convolution)               256x54                  98560       textcnn_1d_001_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv0_relu_fwd(Activation)           256x54                  0           textcnn_1d_001_conv0_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_pool0_fwd(Pooling)                   256x1                   0           textcnn_1d_001_conv0_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv1_fwd(Convolution)               256x53                  131328      textcnn_1d_001_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv1_relu_fwd(Activation)           256x53                  0           textcnn_1d_001_conv1_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_pool1_fwd(Pooling)                   256x1                   0           textcnn_1d_001_conv1_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv2_fwd(Convolution)               256x52                  164096      textcnn_1d_001_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_conv2_relu_fwd(Activation)           256x52                  0           textcnn_1d_001_conv2_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_pool2_fwd(Pooling)                   256x1                   0           textcnn_1d_001_conv2_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_concat0(Concat)                      768x1                   0           textcnn_1d_001_pool0_fwd        \n",
      "                                                                                        textcnn_1d_001_pool1_fwd        \n",
      "                                                                                        textcnn_1d_001_pool2_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_dropout0_fwd(Dropout)                768x1                   0           textcnn_1d_001_concat0          \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_001_dense0_fwd(FullyConnected)           2                       1538        textcnn_1d_001_dropout0_fwd     \n",
      "========================================================================================================================\n",
      "Total params: 395522\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mx.viz.print_summary(\n",
    "    net_1d_00(mx.sym.var('data')), \n",
    "    shape={'data':shape}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (F_o  * F_i * F_w * F_h) + F_o (Bias) : F_o = 아웃풋 채널수(필터수) , F_i = 인풋 채널수,  F_w = 필터 가로폭, F_h = 필터 세로폭\n",
    "## 여기서 인풋 채널 수는 데이터 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98560"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 * 128 * 3 * 1 + 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"326pt\" height=\"930pt\"\n",
       " viewBox=\"0.00 0.00 326.00 930.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 926)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-926 322,-926 322,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"#000000\" cx=\"159\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-24.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_embedding0_fwd -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>textcnn_1d_001_embedding0_fwd</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"206,-166 112,-166 112,-108 206,-108 206,-166\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-132.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">textcnn_1d_001_embedding0_fwd</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_embedding0_fwd&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>textcnn_1d_001_embedding0_fwd&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-97.6567C159,-84.6329 159,-70.3785 159,-58.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-107.7736 154.5001,-97.7736 159,-102.7736 159.0001,-97.7736 159.0001,-97.7736 159.0001,-97.7736 159,-102.7736 163.5001,-97.7737 159,-107.7736 159,-107.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-78.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">56</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_swapaxes0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>textcnn_1d_001_swapaxes0</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"206,-274 112,-274 112,-216 206,-216 206,-274\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-240.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">textcnn_1d_001_swapaxes0</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_swapaxes0&#45;&gt;textcnn_1d_001_embedding0_fwd -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>textcnn_1d_001_swapaxes0&#45;&gt;textcnn_1d_001_embedding0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-205.6567C159,-192.6329 159,-178.3785 159,-166.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-215.7736 154.5001,-205.7736 159,-210.7736 159.0001,-205.7736 159.0001,-205.7736 159.0001,-205.7736 159,-210.7736 163.5001,-205.7737 159,-215.7736 159,-215.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-186.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">56x128</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv0_fwd -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv0_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"94,-382 0,-382 0,-324 94,-324 94,-382\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-355.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3/1, 256</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv0_fwd&#45;&gt;textcnn_1d_001_swapaxes0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv0_fwd&#45;&gt;textcnn_1d_001_swapaxes0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M84.6168,-316.7267C98.951,-302.9044 115.0927,-287.3392 128.667,-274.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.3088,-323.7736 81.3837,-313.5929 80.908,-320.303 84.5073,-316.8323 84.5073,-316.8323 84.5073,-316.8323 80.908,-320.303 87.6309,-320.0716 77.3088,-323.7736 77.3088,-323.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"131\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">128x56</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv0_relu_fwd -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv0_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"94,-490 0,-490 0,-432 94,-432 94,-490\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-463.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-449.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv0_relu_fwd&#45;&gt;textcnn_1d_001_conv0_fwd -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv0_relu_fwd&#45;&gt;textcnn_1d_001_conv0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-421.6567C47,-408.6329 47,-394.3785 47,-382.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-431.7736 42.5001,-421.7736 47,-426.7736 47.0001,-421.7736 47.0001,-421.7736 47.0001,-421.7736 47,-426.7736 51.5001,-421.7737 47,-431.7736 47,-431.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x54</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool0_fwd -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>textcnn_1d_001_pool0_fwd</title>\n",
       "<polygon fill=\"#80b1d3\" stroke=\"#000000\" points=\"94,-598 0,-598 0,-540 94,-540 94,-598\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-571.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pooling</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-557.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">max, 54/54</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool0_fwd&#45;&gt;textcnn_1d_001_conv0_relu_fwd -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>textcnn_1d_001_pool0_fwd&#45;&gt;textcnn_1d_001_conv0_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47,-529.6567C47,-516.6329 47,-502.3785 47,-490.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47,-539.7736 42.5001,-529.7736 47,-534.7736 47.0001,-529.7736 47.0001,-529.7736 47.0001,-529.7736 47,-534.7736 51.5001,-529.7737 47,-539.7736 47,-539.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-510.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x54</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv1_fwd -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv1_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"206,-382 112,-382 112,-324 206,-324 206,-382\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-355.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4/1, 256</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv1_fwd&#45;&gt;textcnn_1d_001_swapaxes0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv1_fwd&#45;&gt;textcnn_1d_001_swapaxes0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-313.6567C159,-300.6329 159,-286.3785 159,-274.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-323.7736 154.5001,-313.7736 159,-318.7736 159.0001,-313.7736 159.0001,-313.7736 159.0001,-313.7736 159,-318.7736 163.5001,-313.7737 159,-323.7736 159,-323.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">128x56</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv1_relu_fwd -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv1_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"206,-490 112,-490 112,-432 206,-432 206,-490\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-463.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-449.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv1_relu_fwd&#45;&gt;textcnn_1d_001_conv1_fwd -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv1_relu_fwd&#45;&gt;textcnn_1d_001_conv1_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-421.6567C159,-408.6329 159,-394.3785 159,-382.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-431.7736 154.5001,-421.7736 159,-426.7736 159.0001,-421.7736 159.0001,-421.7736 159.0001,-421.7736 159,-426.7736 163.5001,-421.7737 159,-431.7736 159,-431.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x53</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool1_fwd -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>textcnn_1d_001_pool1_fwd</title>\n",
       "<polygon fill=\"#80b1d3\" stroke=\"#000000\" points=\"206,-598 112,-598 112,-540 206,-540 206,-598\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-571.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pooling</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-557.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">max, 53/53</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool1_fwd&#45;&gt;textcnn_1d_001_conv1_relu_fwd -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>textcnn_1d_001_pool1_fwd&#45;&gt;textcnn_1d_001_conv1_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-529.6567C159,-516.6329 159,-502.3785 159,-490.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-539.7736 154.5001,-529.7736 159,-534.7736 159.0001,-529.7736 159.0001,-529.7736 159.0001,-529.7736 159,-534.7736 163.5001,-529.7737 159,-539.7736 159,-539.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-510.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x53</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv2_fwd -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv2_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"318,-382 224,-382 224,-324 318,-324 318,-382\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-355.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5/1, 256</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv2_fwd&#45;&gt;textcnn_1d_001_swapaxes0 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv2_fwd&#45;&gt;textcnn_1d_001_swapaxes0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.3832,-316.7267C219.049,-302.9044 202.9073,-287.3392 189.333,-274.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.6912,-323.7736 230.3691,-320.0716 237.092,-320.303 233.4927,-316.8323 233.4927,-316.8323 233.4927,-316.8323 237.092,-320.303 236.6163,-313.5929 240.6912,-323.7736 240.6912,-323.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-294.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">128x56</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv2_relu_fwd -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>textcnn_1d_001_conv2_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"#000000\" points=\"318,-490 224,-490 224,-432 318,-432 318,-490\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-463.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-449.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_conv2_relu_fwd&#45;&gt;textcnn_1d_001_conv2_fwd -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>textcnn_1d_001_conv2_relu_fwd&#45;&gt;textcnn_1d_001_conv2_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271,-421.6567C271,-408.6329 271,-394.3785 271,-382.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"271,-431.7736 266.5001,-421.7736 271,-426.7736 271.0001,-421.7736 271.0001,-421.7736 271.0001,-421.7736 271,-426.7736 275.5001,-421.7737 271,-431.7736 271,-431.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x52</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool2_fwd -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>textcnn_1d_001_pool2_fwd</title>\n",
       "<polygon fill=\"#80b1d3\" stroke=\"#000000\" points=\"318,-598 224,-598 224,-540 318,-540 318,-598\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-571.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pooling</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-557.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">max, 52/52</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_pool2_fwd&#45;&gt;textcnn_1d_001_conv2_relu_fwd -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>textcnn_1d_001_pool2_fwd&#45;&gt;textcnn_1d_001_conv2_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271,-529.6567C271,-516.6329 271,-502.3785 271,-490.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"271,-539.7736 266.5001,-529.7736 271,-534.7736 271.0001,-529.7736 271.0001,-529.7736 271.0001,-529.7736 271,-534.7736 275.5001,-529.7737 271,-539.7736 271,-539.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-510.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x52</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_concat0 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>textcnn_1d_001_concat0</title>\n",
       "<polygon fill=\"#fdb462\" stroke=\"#000000\" points=\"206,-706 112,-706 112,-648 206,-648 206,-706\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-672.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">textcnn_1d_001_concat0</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool0_fwd -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M121.3832,-640.7267C107.049,-626.9044 90.9073,-611.3392 77.333,-598.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"128.6912,-647.7736 118.3691,-644.0716 125.092,-644.303 121.4927,-640.8323 121.4927,-640.8323 121.4927,-640.8323 125.092,-644.303 124.6163,-637.5929 128.6912,-647.7736 128.6912,-647.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-618.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x1</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool1_fwd -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool1_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-637.6567C159,-624.6329 159,-610.3785 159,-598.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-647.7736 154.5001,-637.7736 159,-642.7736 159.0001,-637.7736 159.0001,-637.7736 159.0001,-637.7736 159,-642.7736 163.5001,-637.7737 159,-647.7736 159,-647.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.5\" y=\"-618.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x1</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool2_fwd -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>textcnn_1d_001_concat0&#45;&gt;textcnn_1d_001_pool2_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196.6168,-640.7267C210.951,-626.9044 227.0927,-611.3392 240.667,-598.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.3088,-647.7736 193.3837,-637.5929 192.908,-644.303 196.5073,-640.8323 196.5073,-640.8323 196.5073,-640.8323 192.908,-644.303 199.6309,-644.0716 189.3088,-647.7736 189.3088,-647.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-618.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">256x1</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_dropout0_fwd -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>textcnn_1d_001_dropout0_fwd</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"#000000\" points=\"206,-814 112,-814 112,-756 206,-756 206,-814\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-780.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">textcnn_1d_001_dropout0_fwd</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_dropout0_fwd&#45;&gt;textcnn_1d_001_concat0 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>textcnn_1d_001_dropout0_fwd&#45;&gt;textcnn_1d_001_concat0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-745.6567C159,-732.6329 159,-718.3785 159,-706.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-755.7736 154.5001,-745.7736 159,-750.7736 159.0001,-745.7736 159.0001,-745.7736 159.0001,-745.7736 159,-750.7736 163.5001,-745.7737 159,-755.7736 159,-755.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.5\" y=\"-726.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">768x1</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_dense0_fwd -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>textcnn_1d_001_dense0_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"#000000\" points=\"206,-922 112,-922 112,-864 206,-864 206,-922\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-895.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-881.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2</text>\n",
       "</g>\n",
       "<!-- textcnn_1d_001_dense0_fwd&#45;&gt;textcnn_1d_001_dropout0_fwd -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>textcnn_1d_001_dense0_fwd&#45;&gt;textcnn_1d_001_dropout0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159,-853.6567C159,-840.6329 159,-826.3785 159,-814.2497\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159,-863.7736 154.5001,-853.7736 159,-858.7736 159.0001,-853.7736 159.0001,-853.7736 159.0001,-853.7736 159,-858.7736 163.5001,-853.7737 159,-863.7736 159,-863.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.5\" y=\"-834.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">768x1</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x11e5bf198>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.viz.plot_network(\n",
    "    net_1d_00(mx.sym.var('data')), \n",
    "    shape={'data':shape}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        with autograd.predict_mode():\n",
    "            output = net(data)\n",
    "        \n",
    "        prediction = nd.argmax(output, axis=1)\n",
    "\n",
    "        if (i%50 == 0):\n",
    "            print(\"Samples {}\".format(i*len(data)))\n",
    "        acc.update(preds=prediction, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(net, start_epoch = 0, number_epochs = 50, smoothing_constant = .01):\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)    \n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                        {'learning_rate': LEARNING_RATE, \n",
    "                         'wd':WDECAY, \n",
    "                         'momentum':MOMENTUM})\n",
    "    \n",
    "    train_accuracy = mx.metric.Accuracy()\n",
    "    \n",
    "    for e in range(start_epoch, number_epochs):\n",
    "        for i, (review, label) in enumerate(train_dataloader):\n",
    "            review = review.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record(train_mode=True):\n",
    "                output = net(review)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward() # gradient 계산\n",
    "            trainer.step(review.shape[0]) # graph data(weight) = gradient 반영해서 업데이트\n",
    "            \n",
    "            prediction = nd.argmax(output, axis=1)\n",
    "            train_accuracy.update(preds=prediction, labels=label)\n",
    "\n",
    "            # moving average of the loss\n",
    "            curr_loss = nd.mean(loss).asscalar()\n",
    "            moving_loss = (curr_loss if (i == 0) \n",
    "                           else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "        test_accuracy = evaluate_accuracy(test_dataloader, net)\n",
    "        \n",
    "        print(\"Epoch %s. Loss: %s, Training_acc %s\" % (e, round(moving_loss, 4), round(train_accuracy.get()[1],4)))\n",
    "        print(\"Epoch %s. Loss: %s, Test_acc %s\" % (e, round(moving_loss, 4), round(test_accuracy,4)))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples 0\n",
      "Epoch 0. Loss: 0.6925, Training_acc 0.499\n",
      "Epoch 0. Loss: 0.6925, Test_acc 0.4799\n",
      "Samples 0\n",
      "Epoch 1. Loss: 0.6916, Training_acc 0.5047\n",
      "Epoch 1. Loss: 0.6916, Test_acc 0.4766\n",
      "Samples 0\n",
      "Epoch 2. Loss: 0.6917, Training_acc 0.5086\n",
      "Epoch 2. Loss: 0.6917, Test_acc 0.5446\n",
      "Samples 0\n",
      "Epoch 3. Loss: 0.6909, Training_acc 0.5155\n",
      "Epoch 3. Loss: 0.6909, Test_acc 0.5089\n",
      "Samples 0\n",
      "Epoch 4. Loss: 0.6888, Training_acc 0.5244\n",
      "Epoch 4. Loss: 0.6888, Test_acc 0.5435\n",
      "Samples 0\n",
      "Epoch 5. Loss: 0.6856, Training_acc 0.5304\n",
      "Epoch 5. Loss: 0.6856, Test_acc 0.5379\n",
      "Samples 0\n",
      "Epoch 6. Loss: 0.6847, Training_acc 0.5344\n",
      "Epoch 6. Loss: 0.6847, Test_acc 0.5513\n",
      "Samples 0\n",
      "Epoch 7. Loss: 0.6815, Training_acc 0.5371\n",
      "Epoch 7. Loss: 0.6815, Test_acc 0.5391\n",
      "Samples 0\n",
      "Epoch 8. Loss: 0.6826, Training_acc 0.5391\n",
      "Epoch 8. Loss: 0.6826, Test_acc 0.5424\n",
      "Samples 0\n",
      "Epoch 9. Loss: 0.6774, Training_acc 0.5413\n",
      "Epoch 9. Loss: 0.6774, Test_acc 0.5413\n",
      "Samples 0\n",
      "Epoch 10. Loss: 0.6814, Training_acc 0.5431\n",
      "Epoch 10. Loss: 0.6814, Test_acc 0.5458\n",
      "Samples 0\n",
      "Epoch 11. Loss: 0.6833, Training_acc 0.5454\n",
      "Epoch 11. Loss: 0.6833, Test_acc 0.548\n",
      "Samples 0\n",
      "Epoch 12. Loss: 0.677, Training_acc 0.548\n",
      "Epoch 12. Loss: 0.677, Test_acc 0.5502\n",
      "Samples 0\n",
      "Epoch 13. Loss: 0.6841, Training_acc 0.5504\n",
      "Epoch 13. Loss: 0.6841, Test_acc 0.5658\n",
      "Samples 0\n",
      "Epoch 14. Loss: 0.6636, Training_acc 0.5533\n",
      "Epoch 14. Loss: 0.6636, Test_acc 0.5826\n",
      "Samples 0\n",
      "Epoch 15. Loss: 0.6632, Training_acc 0.5565\n",
      "Epoch 15. Loss: 0.6632, Test_acc 0.5859\n",
      "Samples 0\n",
      "Epoch 16. Loss: 0.6601, Training_acc 0.5597\n",
      "Epoch 16. Loss: 0.6601, Test_acc 0.5926\n",
      "Samples 0\n",
      "Epoch 17. Loss: 0.651, Training_acc 0.563\n",
      "Epoch 17. Loss: 0.651, Test_acc 0.6049\n",
      "Samples 0\n",
      "Epoch 18. Loss: 0.6466, Training_acc 0.5661\n",
      "Epoch 18. Loss: 0.6466, Test_acc 0.5982\n",
      "Samples 0\n",
      "Epoch 19. Loss: 0.6396, Training_acc 0.5695\n",
      "Epoch 19. Loss: 0.6396, Test_acc 0.5993\n",
      "Samples 0\n",
      "Epoch 20. Loss: 0.6306, Training_acc 0.573\n",
      "Epoch 20. Loss: 0.6306, Test_acc 0.6027\n",
      "Samples 0\n",
      "Epoch 21. Loss: 0.6111, Training_acc 0.5766\n",
      "Epoch 21. Loss: 0.6111, Test_acc 0.6183\n",
      "Samples 0\n",
      "Epoch 22. Loss: 0.6084, Training_acc 0.5802\n",
      "Epoch 22. Loss: 0.6084, Test_acc 0.6116\n",
      "Samples 0\n",
      "Epoch 23. Loss: 0.6102, Training_acc 0.5839\n",
      "Epoch 23. Loss: 0.6102, Test_acc 0.6217\n",
      "Samples 0\n",
      "Epoch 24. Loss: 0.6169, Training_acc 0.5876\n",
      "Epoch 24. Loss: 0.6169, Test_acc 0.6283\n",
      "Samples 0\n",
      "Epoch 25. Loss: 0.5968, Training_acc 0.5914\n",
      "Epoch 25. Loss: 0.5968, Test_acc 0.6261\n",
      "Samples 0\n",
      "Epoch 26. Loss: 0.5985, Training_acc 0.5954\n",
      "Epoch 26. Loss: 0.5985, Test_acc 0.6574\n",
      "Samples 0\n",
      "Epoch 27. Loss: 0.5916, Training_acc 0.5994\n",
      "Epoch 27. Loss: 0.5916, Test_acc 0.6473\n",
      "Samples 0\n",
      "Epoch 28. Loss: 0.5599, Training_acc 0.6037\n",
      "Epoch 28. Loss: 0.5599, Test_acc 0.6607\n",
      "Samples 0\n",
      "Epoch 29. Loss: 0.5526, Training_acc 0.608\n",
      "Epoch 29. Loss: 0.5526, Test_acc 0.6696\n",
      "Samples 0\n",
      "Epoch 30. Loss: 0.5522, Training_acc 0.6123\n",
      "Epoch 30. Loss: 0.5522, Test_acc 0.6708\n",
      "Samples 0\n",
      "Epoch 31. Loss: 0.5491, Training_acc 0.6168\n",
      "Epoch 31. Loss: 0.5491, Test_acc 0.6797\n",
      "Samples 0\n",
      "Epoch 32. Loss: 0.5214, Training_acc 0.6214\n",
      "Epoch 32. Loss: 0.5214, Test_acc 0.692\n",
      "Samples 0\n",
      "Epoch 33. Loss: 0.4796, Training_acc 0.626\n",
      "Epoch 33. Loss: 0.4796, Test_acc 0.7109\n",
      "Samples 0\n",
      "Epoch 34. Loss: 0.5108, Training_acc 0.6309\n",
      "Epoch 34. Loss: 0.5108, Test_acc 0.7109\n",
      "Samples 0\n",
      "Epoch 35. Loss: 0.4557, Training_acc 0.6358\n",
      "Epoch 35. Loss: 0.4557, Test_acc 0.7132\n",
      "Samples 0\n",
      "Epoch 36. Loss: 0.45, Training_acc 0.6406\n",
      "Epoch 36. Loss: 0.45, Test_acc 0.7199\n",
      "Samples 0\n",
      "Epoch 37. Loss: 0.427, Training_acc 0.6456\n",
      "Epoch 37. Loss: 0.427, Test_acc 0.7288\n",
      "Samples 0\n",
      "Epoch 38. Loss: 0.3896, Training_acc 0.6505\n",
      "Epoch 38. Loss: 0.3896, Test_acc 0.7355\n",
      "Samples 0\n",
      "Epoch 39. Loss: 0.3712, Training_acc 0.6555\n",
      "Epoch 39. Loss: 0.3712, Test_acc 0.7377\n",
      "Samples 0\n",
      "Epoch 40. Loss: 0.3497, Training_acc 0.6605\n",
      "Epoch 40. Loss: 0.3497, Test_acc 0.7489\n",
      "Samples 0\n",
      "Epoch 41. Loss: 0.326, Training_acc 0.6654\n",
      "Epoch 41. Loss: 0.326, Test_acc 0.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-255:\n",
      "Process Process-253:\n",
      "Process Process-254:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mxnet/gluon/data/dataloader.py\", line 186, in worker_loop\n",
      "    idx, samples = key_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mxnet/gluon/data/dataloader.py\", line 186, in worker_loop\n",
      "    idx, samples = key_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mxnet/gluon/data/dataloader.py\", line 186, in worker_loop\n",
      "    idx, samples = key_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-613d8c0d0794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet_1d_00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_1d_00\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-d7966f6e0210>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(net, start_epoch, number_epochs, smoothing_constant)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# moving average of the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             moving_loss = (curr_loss if (i == 0) \n\u001b[1;32m     26\u001b[0m                            else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net_1d_00 = run_model(net_1d_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1d_00.save_parameters('best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class TextCNN_2D_00(gluon.HybridBlock):\n",
    "    def __init__(self, vocab_size, sequence_length, embed_size, conv_channel, filter_sizes, num_classes, batch_size, **kwargs):\n",
    "        self.conv_channel = conv_channel\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        super(TextCNN_2D_00, self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "            \n",
    "            self.embed = \n",
    "            self.conv0 = \n",
    "            self.pool0 = \n",
    "            \n",
    "            self.conv1 = \n",
    "            self.pool1 = \n",
    "            \n",
    "            self.conv2 =\n",
    "            self.pool2 = \n",
    "            \n",
    "            self.drop1 = \n",
    "            self.out = \n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        ## batch * 56\n",
    "        ## x\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net_2d_00 = TextCNN_2D_00(vocab_size, sequence_length, EMB_OUT, NUM_FILTERS, FILTER_SIZES, NUM_OUTPUTS, BATCH_SIZE)\n",
    "shape = (1, 56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net_2d_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mx.viz.print_summary(\n",
    "    net_2d_00(mx.sym.var('data')), \n",
    "    shape={'data':shape}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net_2d_00 = run_model(net_2d_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: Trainded Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))\n",
    "\n",
    "def norm_vecs_by_row(x):\n",
    "    return x / nd.sqrt(nd.sum(x * x, axis=1)).reshape((-1,1))\n",
    "\n",
    "def get_knn(vocab_vec, vocab_vecs, k):#, word):\n",
    "    word_vec = vocab_vec.reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(vocab_vecs)\n",
    "    dot_prod = nd.dot(vocab_vecs, word_vec)\n",
    "    indices = nd.topk(dot_prod.reshape((vocab_size )), k=k+1, ret_typ='indices')\n",
    "    indices = [int(i.asscalar()) for i in indices]\n",
    "    return list(np.array(vocabulary_inv)[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net_1d_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['textcnn_1d_000_embedding0_weight']\n"
     ]
    }
   ],
   "source": [
    "keys = [i for i in list(net.collect_params().keys()) if 'embedding' in i]\n",
    "print (keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_vec = net.collect_params()[keys[0]].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excellent', 'gentle', 'history', 'unique', 'unlike', 'won']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(embed_vec[vocabulary.get('excellent', '_')], embed_vec, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worse', 'boring', 'loses', 'plodding', 'grating', 'shoot']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(embed_vec[vocabulary.get('worse', '_')], embed_vec, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN_1D_01(gluon.HybridBlock):\n",
    "    def __init__(self, vocab_size, sequence_length, embed_size, conv_channel, filter_sizes, num_classes, batch_size, **kwargs):\n",
    "        self.conv_channel = conv_channel\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        super(TextCNN_1D_01, self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "                        \n",
    "            self.embed = nn.Embedding(input_dim=vocab_size, output_dim=embed_size)\n",
    "\n",
    "            self.conv0 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[0], activation='relu')\n",
    "            self.pool0 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[0] + 1))\n",
    "                        \n",
    "            self.conv1 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[1], activation='relu')\n",
    "            self.pool1 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[1] + 1))\n",
    "            \n",
    "            self.conv2 = nn.Conv1D(channels=conv_channel, kernel_size=filter_sizes[2], activation='relu')\n",
    "            self.pool2 = nn.MaxPool1D(pool_size=(sequence_length - filter_sizes[2] + 1))\n",
    "            \n",
    "            #self.drop1 = nn.Dropout(0.5)\n",
    "            self.out = nn.Dense(num_classes)\n",
    "           \n",
    "    def hybrid_forward(self, F, x):\n",
    "        ## batch * 56\n",
    "        ## x\n",
    "        \n",
    "        ## batch * 56 > batch * 56 * 128\n",
    "        embedded_vectors = self.embed(x)\n",
    "        \n",
    "        ## batch *  56 * 128 > batch * 128 * 56\n",
    "        embedded_vectors = F.swapaxes(embedded_vectors, 1,2)\n",
    "                \n",
    "        ## batch * 128 * 56 > batch * 256 * 54 \n",
    "        conv0_out = self.conv0(embedded_vectors) ## NCW\n",
    "        ## batch * 128 * 56 > batch * 256 * 53\n",
    "        conv1_out = self.conv1(embedded_vectors)\n",
    "        ## batch * 128 * 56 > batch * 256 * 52\n",
    "        conv2_out = self.conv2(embedded_vectors)\n",
    "\n",
    "        ## batch * 256 * 54 > batch * 256 * 1: pool_size(54)\n",
    "        pool0_out = self.pool0(conv0_out)\n",
    "        ## batch * 256 * 53 > batch * 256 * 1: pool_size(53)\n",
    "        pool1_out = self.pool1(conv1_out)\n",
    "        ## batch * 256 * 52 > batch * 256 * 1: pool_size(52)\n",
    "        pool2_out = self.pool2(conv2_out)\n",
    "        \n",
    "        ## batch * [[256 * 1], [256 * 1], [256 * 1]]  \n",
    "        con_list = [pool0_out, pool1_out, pool2_out]\n",
    "                \n",
    "        ## batch * [768* 1] : 768 = 256 *3\n",
    "        fc1_input = F.concat(*con_list, dim=1)\n",
    "        \n",
    "        ## batch * [768 * 1]\n",
    "        #fc1_output = self.drop1(fc1_input)\n",
    "                                        \n",
    "        ## batch * 2    \n",
    "        output = self.out(fc1_input)\n",
    "        return conv0_out, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1d_01 = TextCNN_1D_01(vocab_size, sequence_length, EMB_OUT, NUM_FILTERS, FILTER_SIZES, NUM_OUTPUTS, BATCH_SIZE)\n",
    "shape = (1, 56)\n",
    "net_1d_01.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, out = net_1d_01(mx.sym.var('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                                        Output Shape            Param #     Previous Layer                  \n",
      "========================================================================================================================\n",
      "data(null)                                          56                      0                                           \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_embedding0_fwd(Embedding)            56x128                  0           data                            \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_swapaxes0(SwapAxis)                  128x56                  0           textcnn_1d_010_embedding0_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv0_fwd(Convolution)               256x54                  98560       textcnn_1d_010_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv0_relu_fwd(Activation)           256x54                  0           textcnn_1d_010_conv0_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_pool0_fwd(Pooling)                   256x1                   0           textcnn_1d_010_conv0_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv1_fwd(Convolution)               256x53                  131328      textcnn_1d_010_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv1_relu_fwd(Activation)           256x53                  0           textcnn_1d_010_conv1_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_pool1_fwd(Pooling)                   256x1                   0           textcnn_1d_010_conv1_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv2_fwd(Convolution)               256x52                  164096      textcnn_1d_010_swapaxes0        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_conv2_relu_fwd(Activation)           256x52                  0           textcnn_1d_010_conv2_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_pool2_fwd(Pooling)                   256x1                   0           textcnn_1d_010_conv2_relu_fwd   \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_concat0(Concat)                      768x1                   0           textcnn_1d_010_pool0_fwd        \n",
      "                                                                                        textcnn_1d_010_pool1_fwd        \n",
      "                                                                                        textcnn_1d_010_pool2_fwd        \n",
      "________________________________________________________________________________________________________________________\n",
      "textcnn_1d_010_dense0_fwd(FullyConnected)           2                       1538        textcnn_1d_010_concat0          \n",
      "========================================================================================================================\n",
      "Total params: 395522\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mx.viz.print_summary(\n",
    "    out, \n",
    "    shape={'data':shape}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](imgs/grad_cam.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_conv1D(net, x, y, loss, ctx, params_name='gradcam.params'):\n",
    "    net.load_parameters(params_name, ctx=ctx)\n",
    "    conv_keys = [i for i in list(net.collect_params().keys()) if ('conv' in i) and ('weight' in i)]\n",
    "    last_conv_layer_name = conv_keys[len(conv_keys) -1]\n",
    "    \n",
    "    with autograd.record():\n",
    "            acts, output = net(nd.array([x,],ctx=ctx))\n",
    "            loss_ = loss(output, nd.array([y,],ctx=ctx))\n",
    "            output = nd.SoftmaxActivation(output)\n",
    "            loss_.backward()\n",
    "    \n",
    "    ## acts: Batch * NUM_FILTERS * OUT_CONV (1, 256, 54)\n",
    "    ## output : Batch * NUM_OUTPUTS (1, 2)\n",
    "    \n",
    "    ## F_o  * F_i * F_w  (256, 128, 3) : # F_o = 아웃풋 채널수(NUM_FILTERS) , F_i = 인풋 채널수,  F_w = 필터 가로폭\n",
    "    net_grad = net.conv0.weight.grad()\n",
    "        \n",
    "    #a_{k}^{c}:  F_o (256)\n",
    "    filter_grad = nd.mean(net_grad, axis=(1,2)) # i, j\n",
    "                \n",
    "    #L_{Grad-CAM}^c : (21L ~ 32L)\n",
    "    for i in range(acts.shape[1]):\n",
    "        acts[:,i,:] *= filter_grad[i]\n",
    "    \n",
    "    ## 1장만: NUM_FILTERS * OUT_CONV (256, 54)\n",
    "    acts = nd.squeeze(acts, axis=(0)).asnumpy()\n",
    "    \n",
    "    ## sequence_length * OUT_CONV (56 * 256)\n",
    "    acts =cv2.resize(acts, (sequence_length, NUM_FILTERS))\n",
    "    \n",
    "    ##  sequence_length (56, )\n",
    "    heat = nd.relu(nd.sum(nd.array(acts), axis=0))\n",
    "\n",
    "    return(heat.asnumpy(), loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orgin: demands too much of most viewers\n",
      "Padded: demands_too_much_of_most_viewers__________________________________________________\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "print_eda(shuffle_indices[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heat, loss = grad_cam_conv1D(net_1d_01, x_train[idx], y_train[idx], softmax_cross_entropy, ctx, 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4592699e-06, 2.6545322e-05, 3.9265883e-06, 1.5500223e-06,\n",
       "       6.3334511e-07, 1.2662942e-06, 6.8907229e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07,\n",
       "       4.5485484e-07, 4.5485484e-07, 4.5485484e-07, 4.5485484e-07],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([vocabulary_inv[int(i)] for i in x_train[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hm_tbl = pd.DataFrame({'heat':heat, 'kw':[vocabulary_inv[int(i)] for i in x_train[idx]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_tbl.drop_duplicates(inplace=True)\n",
    "hm_tbl.sort_values(by='heat', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heat</th>\n",
       "      <th>kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.654532e-05</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.926588e-06</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.550022e-06</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.459270e-06</td>\n",
       "      <td>demands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.266294e-06</td>\n",
       "      <td>viewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.890723e-07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.333451e-07</td>\n",
       "      <td>most</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.548548e-07</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           heat       kw\n",
       "1  2.654532e-05      too\n",
       "2  3.926588e-06     much\n",
       "3  1.550022e-06       of\n",
       "0  1.459270e-06  demands\n",
       "5  1.266294e-06  viewers\n",
       "6  6.890723e-07         \n",
       "4  6.333451e-07     most\n",
       "7  4.548548e-07         "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/python/venv/ngram_detectors/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "rcParams.update({'font.size': 17})\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "ax = sns.barplot(x=\"kw\", y=\"heat\", data=hm_tbl[:20])\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('importance')\n",
    "plt.xlabel('keyword')\n",
    "plt.savefig('importances.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soeque1@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
