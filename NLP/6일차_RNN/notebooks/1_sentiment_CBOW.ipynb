{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kionkim/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /opt/venv/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/venv/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /opt/venv/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:36.509211Z",
     "start_time": "2018-07-09T02:32:35.930744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import collections\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:49.292000Z",
     "start_time": "2018-07-09T02:32:48.001145Z"
    }
   },
   "outputs": [],
   "source": [
    "word_freq = collections.Counter()\n",
    "max_len = 0\n",
    "num_rec = 0\n",
    "\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        label, sentence = line.decode('utf8').strip().split('\\t')\n",
    "        words = nltk.word_tokenize(sentence.lower())\n",
    "        if len(words) > max_len:\n",
    "            max_len = len(words)\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "        num_rec += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:50.219676Z",
     "start_time": "2018-07-09T02:32:50.205590Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 2000\n",
    "MAX_SENTENCE_LENGTH = 40\n",
    "# most_common output -> list\n",
    "word2idx = {x[0]: i+2 for i, x in enumerate(word_freq.most_common(MAX_FEATURES - 2))}\n",
    "word2idx ['PAD'] = 0\n",
    "word2idx['UNK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:51.009574Z",
     "start_time": "2018-07-09T02:32:51.005281Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2word= {i:v for v, i in word2idx.items()}\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:53.128199Z",
     "start_time": "2018-07-09T02:32:51.767573Z"
    }
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "origin_txt = []\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        _label, _sentence = line.decode('utf8').strip().split('\\t')\n",
    "        origin_txt.append(_sentence)\n",
    "        y.append(int(_label))\n",
    "        words = nltk.word_tokenize(_sentence.lower())\n",
    "        _seq = []\n",
    "        for word in words:\n",
    "            if word in word2idx.keys():\n",
    "                _seq.append(word2idx[word])\n",
    "            else:\n",
    "                _seq.append(word2idx['UNK'])\n",
    "        if len(_seq) < MAX_SENTENCE_LENGTH:\n",
    "            _seq.extend([0] * ((MAX_SENTENCE_LENGTH) - len(_seq)))\n",
    "        else:\n",
    "            _seq = _seq[:MAX_SENTENCE_LENGTH]\n",
    "        x.append(_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:58.902758Z",
     "start_time": "2018-07-09T02:32:58.855252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yn</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yn  index\n",
       "0   0   3091\n",
       "1   1   3995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = ['yn']).reset_index().groupby('yn').count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence representation: Average of BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:01.697120Z",
     "start_time": "2018-07-09T02:33:01.693872Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(x, vocab_size):\n",
    "    res = np.zeros(shape = (vocab_size))\n",
    "    res[x] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:05.900318Z",
     "start_time": "2018-07-09T02:33:04.086785Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = np.array([np.sum(np.array([one_hot(word, MAX_FEATURES) for word in example]), axis = 0) for example in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process - tr/va split and define iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:08.625731Z",
     "start_time": "2018-07-09T02:33:08.540505Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_idx = np.random.choice(range(x_1.shape[0]), int(x_1.shape[0] * .8))\n",
    "va_idx = [x for x in range(x_1.shape[0]) if x not in tr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:10.348133Z",
     "start_time": "2018-07-09T02:33:10.302009Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_x = x_1[tr_idx, :]\n",
    "tr_y = [y[i] for i in tr_idx]\n",
    "va_x = x_1[va_idx, :]\n",
    "va_y = [y[i] for i in va_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:19.035519Z",
     "start_time": "2018-07-09T02:33:19.031513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5668, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "* If we transform sentence into machine-understandable form via average of BOW, we can separate representation and classification\n",
    "* Here, we will apply various classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:20:27.240271Z",
     "start_time": "2018-06-16T16:20:27.222750Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:21:45.266083Z",
     "start_time": "2018-06-16T16:21:24.711438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:11.861052Z",
     "start_time": "2018-06-16T16:22:11.679670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(va_x)\n",
    "pred_xgb = [round(val) for val in y_pred_xgb]\n",
    "\n",
    "# Check predictions\n",
    "#pred_pd= pd.DataFrame(pred_xgb, columns = ['pred']).reset_index()\n",
    "#pred_pd.groupby(['pred']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:54.227408Z",
     "start_time": "2018-06-16T16:22:54.219056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.68%\n"
     ]
    }
   ],
   "source": [
    "accuracy_xgb = accuracy_score(va_y, pred_xgb)\n",
    "print('Accuracy: %.2f%%'%(accuracy_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:59.099704Z",
     "start_time": "2018-06-16T16:22:59.064160Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:02.455789Z",
     "start_time": "2018-06-16T16:23:02.046982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:04.872970Z",
     "start_time": "2018-06-16T16:23:04.813480Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(va_x)\n",
    "pred_rf = [round(val) for val in y_pred_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:06.935466Z",
     "start_time": "2018-06-16T16:23:06.927963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.87%\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(va_y, pred_rf)\n",
    "print('Accuracy: %.2f%%'%(accuracy_rf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:08.901361Z",
     "start_time": "2018-06-16T16:23:08.897570Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:27:36.872185Z",
     "start_time": "2018-06-16T16:27:36.865713Z"
    }
   },
   "outputs": [],
   "source": [
    "models = (svm.SVC(kernel = 'linear', C = 1.0), # C: SVM Regularization parameter\n",
    "          svm.LinearSVC(C = 1.0),\n",
    "          svm.SVC(kernel = 'rbf', gamma = .7, C = 1.0),\n",
    "          svm.SVC(kernel = 'poly', degree = 3, C = 1.0)\n",
    ")\n",
    "\n",
    "models = (mdl.fit(tr_x, tr_y) for mdl in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:30:16.093817Z",
     "start_time": "2018-06-16T16:27:40.386965Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_svm = (mdl.predict(va_x) for mdl in models)\n",
    "pred_svm = [[round(val) for val in _pred] for _pred in y_pred_svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:31:25.546462Z",
     "start_time": "2018-06-16T16:31:25.528584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [99.08 99.05 94.02 56.06]\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm = [accuracy_score(va_y, pred) for pred in pred_svm]\n",
    "print('Accuracy: {}'.format(np.round(accuracy_svm, 4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:16.199066Z",
     "start_time": "2018-06-16T16:35:16.144108Z"
    }
   },
   "outputs": [],
   "source": [
    "va_txt = pd.DataFrame(np.array([origin_txt[idx] for idx in va_idx]), columns = ['txt'])\n",
    "pred_rf_pd = pd.DataFrame(pred_rf, columns  = ['pred_rf'])\n",
    "pred_xgb_pd = pd.DataFrame(pred_xgb, columns  = ['pred_xgb'])\n",
    "pred_svm_svc_pd = pd.DataFrame(pred_svm[2], columns  = ['pred_svm'])\n",
    "label_pd = pd.DataFrame(va_y, columns = ['label'])\n",
    "result = pd.concat([va_txt, pred_rf_pd, pred_xgb_pd, pred_svm_svc_pd, label_pd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:17.654932Z",
     "start_time": "2018-06-16T16:35:17.639960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>pred_xgb</th>\n",
       "      <th>pred_svm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that's not even an exaggeration ) and at midni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought the Da Vinci Code was a pretty good ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Da Vinci Code was REALLY good.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE DA VINCI CODE is AN AWESOME BOOK....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thing is, I enjoyed The Da Vinci Code.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  pred_rf  pred_xgb  \\\n",
       "0  that's not even an exaggeration ) and at midni...        1         0   \n",
       "1  I thought the Da Vinci Code was a pretty good ...        1         1   \n",
       "2                 The Da Vinci Code was REALLY good.        0         0   \n",
       "3           THE DA VINCI CODE is AN AWESOME BOOK....        1         1   \n",
       "4             Thing is, I enjoyed The Da Vinci Code.        0         0   \n",
       "\n",
       "   pred_svm  label  \n",
       "0         1      1  \n",
       "1         1      1  \n",
       "2         1      1  \n",
       "3         1      1  \n",
       "4         1      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:20.710584Z",
     "start_time": "2018-06-16T16:35:20.698418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of error case from RF : 67\n",
      "# of error case from XGB: 73\n",
      "# of error case from SVM: 188\n"
     ]
    }
   ],
   "source": [
    "print('# of error case from RF : {}'.format(result[result['pred_rf'] != result['label']].shape[0]))\n",
    "print('# of error case from XGB: {}'.format(result[result['pred_xgb'] != result['label']].shape[0]))\n",
    "print('# of error case from SVM: {}'.format(result[result['pred_svm'] != result['label']].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:11.580851Z",
     "start_time": "2018-06-16T16:38:11.082714Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "context = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:12.303080Z",
     "start_time": "2018-06-16T16:38:12.297603Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, input_dim, emb_dim, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.embed = nn.Embedding(input_dim = input_dim, output_dim = emb_dim)\n",
    "            self.dense1 = nn.Dense(64)\n",
    "            #self.dense2 = nn.Dense(32, activation = 'relu')\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dense2 = nn.Dense(2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn(x)\n",
    "        x = nd.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:13.587224Z",
     "start_time": "2018-06-16T16:38:13.582092Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_f(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    #print('pred = {}'.format(pred))\n",
    "    #print('label = {}'.format(label))\n",
    "    corr = ((pred > 0.5) == label)*1.\n",
    "    return (((pred > 0.5) == label)*1.).mean()\n",
    "tr_metric = mx.metric.CustomMetric(acc_f)\n",
    "va_metric = mx.metric.CustomMetric(acc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:20.656050Z",
     "start_time": "2018-06-16T16:38:20.647311Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "os.environ['MXNET_ENGINE_TYPE'] = 'NaiveEngine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:31.105063Z",
     "start_time": "2018-06-16T16:38:30.894757Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = mx.io.NDArrayIter(data=[tr_x, tr_y], batch_size=batch_size, shuffle = False)\n",
    "valid_data = mx.io.NDArrayIter(data=[va_x, va_y], batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:39:22.206Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLP(input_dim = MAX_FEATURES, emb_dim = 50)\n",
    "mlp.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "loss = gluon.loss.SoftmaxCELoss()\n",
    "trainer = gluon.Trainer(mlp.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b7236dab4b4459a21446ffa67053dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: tr_loss = [0.06689082], tr_acc= 0.9777036516853933, va_loss = [0.71115905], va_acc= 0.6271875\n",
      "Epoch 1: tr_loss = [0.00672516], tr_acc= 0.9989466292134831, va_loss = [0.13715069], va_acc= 0.9653125\n",
      "Epoch 2: tr_loss = [0.00187768], tr_acc= 0.9996488764044944, va_loss = [0.23311073], va_acc= 0.9325\n",
      "Epoch 3: tr_loss = [0.00110336], tr_acc= 0.9998244382022472, va_loss = [0.03475095], va_acc= 0.9865625\n",
      "Epoch 4: tr_loss = [0.00075083], tr_acc= 0.9998244382022472, va_loss = [0.03498295], va_acc= 0.9865625\n",
      "Epoch 5: tr_loss = [0.00064765], tr_acc= 0.9996488764044944, va_loss = [0.03444985], va_acc= 0.9859375\n",
      "Epoch 6: tr_loss = [0.0005337], tr_acc= 0.9998244382022472, va_loss = [0.03331061], va_acc= 0.9871875\n",
      "Epoch 7: tr_loss = [0.00047138], tr_acc= 0.9998244382022472, va_loss = [0.03248437], va_acc= 0.9871875\n",
      "Epoch 8: tr_loss = [0.00042152], tr_acc= 0.9998244382022472, va_loss = [0.03190098], va_acc= 0.9875\n",
      "Epoch 9: tr_loss = [0.00037398], tr_acc= 0.9998244382022472, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(n_epoch), desc = 'epoch'):\n",
    "    ## Training\n",
    "    train_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(train_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        with autograd.record():\n",
    "            _out = mlp(_dat)\n",
    "            _los = nd.sum(loss(_out, _label)) # 배치의 크기만큼의 loss가 나옴\n",
    "            _los.backward()\n",
    "        trainer.step(_dat.shape[0])\n",
    "        n_obs += _dat.shape[0]\n",
    "        #print(n_obs)\n",
    "        _total_los += nd.sum(_los).asnumpy()\n",
    "        # Epoch loss를 구하기 위해서 결과물을 계속 쌓음\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy()) # 두번째 컬럼의 확률이 예측 확률\n",
    "        label.extend(_label.asnumpy())\n",
    "    #print(pred)\n",
    "    #print([round(p) for p in pred]) # 기본이 float임\n",
    "    #print(label)\n",
    "    #print('**** ' + str(n_obs))\n",
    "    #print(label[:10])\n",
    "    #print(pred[:10])\n",
    "    #print([round(p) for p in pred][:10])\n",
    "    tr_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    tr_loss = _total_los/n_obs\n",
    "    \n",
    "    ### Evaluate training\n",
    "    valid_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(valid_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        _out = mlp(_dat)\n",
    "        _pred_score = nd.softmax(_out)\n",
    "        n_obs += _dat.shape[0]\n",
    "        _total_los += nd.sum(loss(_out, _label)).asnumpy()\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy())\n",
    "        label.extend(_label.asnumpy())\n",
    "    va_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    va_loss = _total_los/n_obs\n",
    "    tqdm.write('Epoch {}: tr_loss = {}, tr_acc= {}, va_loss = {}, va_acc= {}'.format(epoch, tr_loss, tr_acc, va_loss, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = mlp(nd.array(va_x, ctx = context))\n",
    "# softmax를 적용하고\n",
    "# 두번째 열을 뽑아와서\n",
    "# nd.round 함수를 적용해서 0/1 예측값을 얻고\n",
    "# numpy array로 바꾸고\n",
    "# 첫번째 원소를 뽑아서 예측 label로 사용\n",
    "pred_mlp = [nd.round(val).asnumpy()[0] for val in nd.softmax(y_pred_mlp)[:, 1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.76%\n"
     ]
    }
   ],
   "source": [
    "accuracy_mlp = accuracy_score(va_y, pred_mlp)\n",
    "print('Accuracy: %.2f%%'%(accuracy_mlp * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense1 = nn.Dense(64)\n",
    "            #self.dense2 = nn.Dense(32, activation = 'relu')\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dense2 = nn.Dense(2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn(x)\n",
    "        x = nd.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_no_embedding = MLP()\n",
    "mlp_no_embedding.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "loss = gluon.loss.SoftmaxCELoss()\n",
    "trainer = gluon.Trainer(mlp_no_embedding.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd1c427eb4c483a9f8297d1adbc6738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: tr_loss = [0.19050199], tr_acc= 0.9357443820224719, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 1: tr_loss = [0.01419211], tr_acc= 0.9985955056179775, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 2: tr_loss = [0.00433564], tr_acc= 0.9996488764044944, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 3: tr_loss = [0.0024576], tr_acc= 0.9996488764044944, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 4: tr_loss = [0.00149932], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 5: tr_loss = [0.00096115], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 6: tr_loss = [0.00070163], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 7: tr_loss = [0.00055028], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 8: tr_loss = [0.00044363], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "Epoch 9: tr_loss = [0.00036642], tr_acc= 1.0, va_loss = [0.0317603], va_acc= 0.9878125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(n_epoch), desc = 'epoch'):\n",
    "    ## Training\n",
    "    train_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(train_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        with autograd.record():\n",
    "            _out = mlp_no_embedding(_dat)\n",
    "            _los = nd.sum(loss(_out, _label)) # 배치의 크기만큼의 loss가 나옴\n",
    "            _los.backward()\n",
    "        trainer.step(_dat.shape[0])\n",
    "        n_obs += _dat.shape[0]\n",
    "        #print(n_obs)\n",
    "        _total_los += nd.sum(_los).asnumpy()\n",
    "        # Epoch loss를 구하기 위해서 결과물을 계속 쌓음\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy()) # 두번째 컬럼의 확률이 예측 확률\n",
    "        label.extend(_label.asnumpy())\n",
    "    #print(pred)\n",
    "    #print([round(p) for p in pred]) # 기본이 float임\n",
    "    #print(label)\n",
    "    #print('**** ' + str(n_obs))\n",
    "    #print(label[:10])\n",
    "    #print(pred[:10])\n",
    "    #print([round(p) for p in pred][:10])\n",
    "    tr_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    tr_loss = _total_los/n_obs\n",
    "    \n",
    "    ### Evaluate training\n",
    "    valid_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(valid_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        _out = mlp(_dat)\n",
    "        _pred_score = nd.softmax(_out)\n",
    "        n_obs += _dat.shape[0]\n",
    "        _total_los += nd.sum(loss(_out, _label)).asnumpy()\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy())\n",
    "        label.extend(_label.asnumpy())\n",
    "    va_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    va_loss = _total_los/n_obs\n",
    "    tqdm.write('Epoch {}: tr_loss = {}, tr_acc= {}, va_loss = {}, va_acc= {}'.format(epoch, tr_loss, tr_acc, va_loss, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_no_embedding = mlp_no_embedding(nd.array(va_x, ctx = context))\n",
    "# softmax를 적용하고\n",
    "# 두번째 열을 뽑아와서\n",
    "# nd.round 함수를 적용해서 0/1 예측값을 얻고\n",
    "# numpy array로 바꾸고\n",
    "# 첫번째 원소를 뽑아서 예측 label로 사용\n",
    "pred_mlp_no_embedding = [nd.round(val).asnumpy()[0] for val in nd.softmax(y_pred_mlp)[:, 1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.76%\n"
     ]
    }
   ],
   "source": [
    "accuracy_mlp_no_embedding = accuracy_score(va_y, pred_mlp_no_embedding)\n",
    "print('Accuracy: %.2f%%'%(accuracy_mlp_no_embedding * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_txt = pd.DataFrame(np.array([origin_txt[idx] for idx in va_idx]), columns = ['txt'])\n",
    "pred_mlp_no_embedding_pd = pd.DataFrame(pred_mlp_no_embedding, columns  = ['pred_mlp_no_embedding'])\n",
    "label_pd = pd.DataFrame(va_y, columns = ['label'])\n",
    "result = pd.concat([va_txt, pred_mlp_no_embedding_pd, label_pd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['pred_mlp_no_embedding'] != result['label']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[9.9993134e-01 9.9995065e-01 9.9994564e-01 9.9993896e-01 9.9991822e-01\n",
       " 9.9994397e-01 9.9994290e-01 9.9993896e-01 9.9993610e-01 1.7375102e-02\n",
       " 2.7934110e-03 3.2467667e-02 1.5153956e-05 7.8517452e-02 7.9589250e-04\n",
       " 3.2973409e-01 2.2070535e-07 9.3622890e-05 8.1146415e-04 1.4700463e-05\n",
       " 1.6620104e-05 3.6849084e-05 4.6369656e-05 1.1681904e-04 1.2161185e-02\n",
       " 2.9147562e-01 3.3054352e-02 4.5397133e-05 1.2546702e-04 6.2344661e-08\n",
       " 3.3202698e-05 5.2164240e-05 9.2523689e-05 1.2638983e-04 7.7245044e-05\n",
       " 1.0179579e-04 3.1921965e-05 2.9245422e-05 6.6700428e-05 2.1928401e-05\n",
       " 1.0722188e-04 2.4290648e-05 1.1346096e-02 3.3071337e-05 9.2709051e-05\n",
       " 6.6700428e-05 1.0328748e-01 4.9137998e-05 2.8014177e-04 9.0252848e-05\n",
       " 7.4576818e-08 1.1681904e-04 9.5113588e-05 4.1982674e-04 2.0698872e-03\n",
       " 3.0947605e-04 7.0564187e-04 1.7729572e-04 6.6714069e-06 1.9732476e-04\n",
       " 6.1972554e-05 3.5129324e-05 1.0271466e-02 3.1249336e-04]\n",
       "<NDArray 64 @gpu(0)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pred_score[:, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
