{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 글루온 신경망 언어 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 기존 언어모델의 한계를 설명한 이유는 기존의 한계나 단점을 딥러닝이 멋지게 해결했기 때문이다.  앞서 설명한 피드 포워드(feed-forward) 신경망 그리고 임베딩으로 단어를 실수 벡터 공간으로 사영할 수 있게 되어 데이터 희소화 문제를 해결했으며, 더 나아가 일반화를 꾀할 수 있었다. 예를 들어 \"빨간 자동차\"가 코퍼스에 없다 하더라도 \"빨간\", \"자동차\" 두 단어의 임베딩 벡터를 평균하여 \"빨간 자동차\"의 벡터를 생성할 수 있을 것이다.  또한 RNN으로 장기 문맥 정보를 반영하는게 용이해졌다. 물론 RNN이 시퀀스가 길어질때 그래디언트 소실문제가 있었으나, LSTM이나 GRU로 상당부분 해결이 되었다. 게다가 기존의 비지도학습 기반의 언어모델 생성을 신경망 기반의 지도학습으로 변화시켰다.\n",
    "\n",
    "몇마디 문장으로 기존 언어모델에서 신경망 언어모델로의 변화 특징을 기술했지만, 이 부분의 기술진보 역사가 짧은편은 아니다. 여기서는 모든 변화를 설명하기 보다는 위 단점을 해소한 하나의 신경망 언어모델을 GluonNLP를 이용해 살펴보고 몇가지 다은 언어모델을 전이학습으로 활용해보는 방법을 설명하도록 하겠다. \n",
    "\n",
    "신경망 언어모델로 오게 되면서 언어모델 자체로서의 의미보다는 다양한 NLP관련 모형을 만들때 임베딩과 함게 핵심적인 역할을 수행하는 딥러닝 컴포넌트의 역할을 수행하게 되었으며, 이 때문에 범용적인 다양한 언어모델이 제안되었고 이를 기반으로 한 전이학습 등으로 기계번역 등의 영역에서 성능향상을 이뤄왔다. 따라서 직접 언어모델을 생성하거나 혹은 잘 만들어진 언어모델을 사용하여 목적에 맞는 모형을 생성하는 경험은 앞으로 NLP의 영역의 어플리케이션을 만드는데 큰 도움이 될 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from mxnet.gluon import nn, rnn\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, gluon, autograd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://raw.githubusercontent.com/yxtay/char-rnn-text-generation/master/data/tinyshakespeare.txt --output tinyshakespeare.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n"
     ]
    }
   ],
   "source": [
    "!head tinyshakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -35000 tinyshakespeare.txt > tinyshakespeare_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -4999 tinyshakespeare.txt > tinyshakespeare_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = list(itertools.chain.from_iterable(open('tinyshakespeare_train.txt', 'rt')))\n",
    "corpus_test = list(itertools.chain.from_iterable(open('tinyshakespeare_test.txt', 'rt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "seq_size = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = nlp.data.Counter(corpus_train)\n",
    "vocab = nlp.Vocab(counter, unknown_token='<unk>',  min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Language Model 학습을 위한 학습셋을 생성하기 위한 함수 \n",
    "#주의 (seq_len, batch_size) 형태의 데이터 배치를 생성한다. \n",
    "bptt_bfy = nlp.data.batchify.CorpusBPTTBatchify(vocab, seq_size, batch_size, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bptt_bfy는 list를 입력받고, mxnet.gluon.data.SimpleDataset 객체를 리턴하는 함수\n",
    "\n",
    "train_data, test_data = [bptt_bfy(d) for d in (corpus_train, corpus_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : \n",
      "First Citizen:\n",
      "Before we proceed an\n",
      "output : \n",
      "irst Citizen:\n",
      "Before we proceed any\n",
      "input : \n",
      "y further, hear me speak.\n",
      "\n",
      "All:\n",
      "Spe\n",
      "output : \n",
      " further, hear me speak.\n",
      "\n",
      "All:\n",
      "Spea\n",
      "input : \n",
      "ak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are \n",
      "output : \n",
      "k, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are a\n",
      "input : \n",
      "all resolved rather to die than to \n",
      "output : \n",
      "ll resolved rather to die than to f\n"
     ]
    }
   ],
   "source": [
    "it = 0 \n",
    "for i,j in train_data:\n",
    "    #각 배치의 첫번째 데이터를 출력한다. \n",
    "    print('input : \\n'+ ''.join([vocab.idx_to_token[a] for a in i[:,0].asnumpy().astype('int')]))\n",
    "    print('output : \\n'+ ''.join([vocab.idx_to_token[a] for a in j[:,0].asnumpy().astype('int')]))\n",
    "    it += 1\n",
    "    if it > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLM(nn.HybridBlock):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(StandardLM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size \n",
    "        self.hidden_size = hidden_size \n",
    "\n",
    "        with self.name_scope():        \n",
    "            self.embedding = nn.Embedding(input_dim=self.vocab_size, output_dim=self.embed_size)\n",
    "            self.drop = nn.Dropout(0.2)\n",
    "            self.encoder = rnn.LSTM(hidden_size=hidden_size, num_layers=2, dropout=0.2)\n",
    "            self.decoder = nn.Dense(self.vocab_size, flatten=False)\n",
    "        \n",
    "    def hybrid_forward(self, F, x, hidden):\n",
    "        embed = self.drop(self.embedding(x))\n",
    "        lstm_out, hidden_o = self.encoder(embed, hidden)\n",
    "        return(self.decoder(lstm_out), hidden_o)\n",
    "    \n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return(self.encoder.begin_state(*args, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab.idx_to_token)\n",
    "model = StandardLM(vocab_size, embed_size=200, hidden_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "trainer = gluon.Trainer(model.collect_params(), 'adam')\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardLM(\n",
       "  (decoder): Dense(None -> 67, linear)\n",
       "  (encoder): LSTM(None -> 200, TNC, num_layers=2, dropout=0.2)\n",
       "  (drop): Dropout(p = 0.2, axes=())\n",
       "  (embedding): Embedding(67 -> 200, float32)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_source, batch_size, ctx):\n",
    "    total_L = 0.0\n",
    "    ntotal = 0\n",
    "    hidden = model.begin_state(batch_size, func=nd.zeros, ctx=ctx)\n",
    "    for i, (data, target) in enumerate(data_source):\n",
    "        data = data.as_in_context(ctx)\n",
    "        target = target.as_in_context(ctx)\n",
    "        output, hidden = model(data, hidden)\n",
    "        hidden = [h.detach() for h in hidden]\n",
    "        L = loss(output, target)\n",
    "        total_L += nd.sum(L).asscalar()\n",
    "        ntotal += L.size\n",
    "    return(total_L / ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity : $\\exp^{- \\frac{1}{n} \\sum_{i=1}^n \\log_2LM(w_i|w_{1:i-1})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perplexity(model, data, batch_size, ctx):\n",
    "    perp = mx.metric.Perplexity(ignore_label=None)\n",
    "    hidden = model.begin_state(batch_size, func=nd.zeros, ctx=ctx)\n",
    "    for i, (data, target) in enumerate(data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        target = target.as_in_context(ctx)\n",
    "        output, hidden = model(data, hidden)\n",
    "        hidden = [h.detach() for h in hidden]\n",
    "        perp.update(target, output)\n",
    "    return(perp.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, epochs):\n",
    "    start_train_time = time.time()\n",
    "    Ltr = []\n",
    "    Lte = []\n",
    "    perp = []\n",
    "    for epoch in range(epochs):\n",
    "        hidden = model.begin_state(batch_size, func=nd.zeros, ctx=ctx)\n",
    "        L = []\n",
    "        for i, (data, target) in enumerate(tqdm(train_data)):\n",
    "            data = data.as_in_context(ctx)\n",
    "            target = target.as_in_context(ctx)\n",
    "            hidden = [h.detach() for h in hidden]\n",
    "            with autograd.record():\n",
    "                output, hidden = model(data, hidden)\n",
    "                batch_L = loss(output, target)\n",
    "                L.append(batch_L.asnumpy())\n",
    "            batch_L.backward()\n",
    "            trainer.step(data.shape[1])\n",
    "        test_loss = evaluate(model, test_data, batch_size, ctx)  \n",
    "        train_loss = np.array(L).mean()\n",
    "        perplexity = eval_perplexity(model, test_data, batch_size, ctx)\n",
    "        \n",
    "        Ltr.append(train_loss)\n",
    "        Lte.append(test_loss)\n",
    "        perp.append(perplexity)\n",
    "        print('epoch : {} ;train loss : {} ;test loss : {} ; test perplexity  : {}'.format(epoch, train_loss, test_loss, perplexity))  \n",
    "    return(Ltr, Lte, perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.56it/s]\n",
      "  0%|          | 3/942 [00:00<00:32, 29.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 ;train loss : 2.156374931335449 ;test loss : 1.8512018540326287 ; test perplexity  : 0.24608353309974376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.67it/s]\n",
      "  0%|          | 3/942 [00:00<00:32, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 ;train loss : 1.6528326272964478 ;test loss : 1.728211059203955 ; test perplexity  : 0.21636880666643651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.69it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2 ;train loss : 1.5264644622802734 ;test loss : 1.651648197425943 ; test perplexity  : 0.20110196464653254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.62it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3 ;train loss : 1.461790680885315 ;test loss : 1.6216540067565113 ; test perplexity  : 0.1923264080602213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.68it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4 ;train loss : 1.4215331077575684 ;test loss : 1.594846079300861 ; test perplexity  : 0.18675702921171003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.63it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5 ;train loss : 1.3917092084884644 ;test loss : 1.5759037324646656 ; test perplexity  : 0.18042122783385314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.66it/s]\n",
      "  0%|          | 3/942 [00:00<00:32, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6 ;train loss : 1.3699151277542114 ;test loss : 1.5627451975663311 ; test perplexity  : 0.1768341563087865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.68it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7 ;train loss : 1.3523614406585693 ;test loss : 1.5570270149075256 ; test perplexity  : 0.17533362161928318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.69it/s]\n",
      "  0%|          | 3/942 [00:00<00:32, 29.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8 ;train loss : 1.338131308555603 ;test loss : 1.54912386524434 ; test perplexity  : 0.17326621894500038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.61it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9 ;train loss : 1.3263251781463623 ;test loss : 1.5399158802925468 ; test perplexity  : 0.17160997756820048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.61it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10 ;train loss : 1.3157912492752075 ;test loss : 1.5476586294918357 ; test perplexity  : 0.1685901722689627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.62it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 11 ;train loss : 1.30707585811615 ;test loss : 1.544392904256429 ; test perplexity  : 0.1674097528826944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.62it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 12 ;train loss : 1.2990243434906006 ;test loss : 1.546013604721674 ; test perplexity  : 0.16573490194632112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.64it/s]\n",
      "  0%|          | 3/942 [00:00<00:33, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 13 ;train loss : 1.29240882396698 ;test loss : 1.5487839358765967 ; test perplexity  : 0.16493288015760948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.67it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 14 ;train loss : 1.2858871221542358 ;test loss : 1.5513646046797624 ; test perplexity  : 0.16403128751397722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.65it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 15 ;train loss : 1.2802140712738037 ;test loss : 1.5407149142005434 ; test perplexity  : 0.16295455487812738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.66it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 16 ;train loss : 1.275181531906128 ;test loss : 1.5456598838265776 ; test perplexity  : 0.1635148370276148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.70it/s]\n",
      "  0%|          | 3/942 [00:00<00:33, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 17 ;train loss : 1.2707302570343018 ;test loss : 1.54494518541059 ; test perplexity  : 0.16020340415765802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.65it/s]\n",
      "  0%|          | 3/942 [00:00<00:31, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 18 ;train loss : 1.2668492794036865 ;test loss : 1.544065261602688 ; test perplexity  : 0.16174261436688117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [00:34<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 19 ;train loss : 1.262573003768921 ;test loss : 1.5449989025761672 ; test perplexity  : 0.16110228806388893\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, perplexity = train(model, train_data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb002407be0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({\"train_loss\":train_loss, \"test_loss\":test_loss}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation(txt_seq, model, vocab):\n",
    "    txt_seq = list(txt_seq) \n",
    "    hidden = model.begin_state(batch_size=1, func=nd.zeros, ctx=ctx)\n",
    "    i = 0\n",
    "    char_seq = []\n",
    "    with autograd.record(train_mode=False):\n",
    "        for tkn in txt_seq:\n",
    "            res, hidden = model(nd.array([[vocab[tkn],]]).as_in_context(ctx), hidden)\n",
    "            tkn = tkn\n",
    "            char_seq.append(tkn)\n",
    "        while tkn != '<eos>':\n",
    "            i += 1\n",
    "            res, hidden = model(nd.array([[vocab[tkn],]]).as_in_context(ctx), hidden)\n",
    "            tkn = vocab.idx_to_token[nd.argmax(res, axis=2).asnumpy().flatten()[0].astype('int')]\n",
    "            char_seq.append(tkn)\n",
    "            if i > 150:\n",
    "                break\n",
    "    return(\"\".join(char_seq))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are all resolved rather aport\\nThat we have seen the world and the devil and death,\\nAnd therefore have seen the world and the devil\\nThat we have seen the world and the devil an'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation(\"You are all resolved rather \", model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.model.awd_lstm_lm_1150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWDRNN(\n",
      "  (encoder): Sequential(\n",
      "    (0): LSTM(400 -> 1150, TNC)\n",
      "    (1): LSTM(1150 -> 1150, TNC)\n",
      "    (2): LSTM(1150 -> 400, TNC)\n",
      "  )\n",
      "  (embedding): HybridSequential(\n",
      "    (0): Embedding(33278 -> 400, float32)\n",
      "    (1): Dropout(p = 0.65, axes=(0,))\n",
      "  )\n",
      "  (decoder): HybridSequential(\n",
      "    (0): Dense(400 -> 33278, linear)\n",
      "  )\n",
      ")\n",
      "Vocab(size=33278, unk=\"<unk>\", reserved=\"['<eos>']\")\n"
     ]
    }
   ],
   "source": [
    "awd_model_name = 'awd_lstm_lm_1150'\n",
    "dataset_name = 'wikitext-2'\n",
    "awd_model, vocab = nlp.model.get_model(\n",
    "    awd_model_name,\n",
    "    dataset_name=dataset_name,\n",
    "    pretrained=True,\n",
    "    ctx=mx.gpu())\n",
    "print(awd_model)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
